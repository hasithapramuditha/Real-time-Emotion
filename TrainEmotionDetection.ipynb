{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gwt94wQimn6",
        "outputId": "14b3571b-6e2e-4b94-e6d9-92773d755dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/msambare/fer2013?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60.3M/60.3M [00:02<00:00, 28.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset moved to: /content/\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "\n",
        "# Move dataset to /content/\n",
        "new_path = \"/content/\"\n",
        "shutil.move(path, new_path)\n",
        "\n",
        "print(\"Dataset moved to:\", new_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required packages\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize image data generator with rescaling\n",
        "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Preprocess all test images\n",
        "train_generator = train_data_gen.flow_from_directory(\n",
        "        '1/train',\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Preprocess all train images\n",
        "validation_generator = validation_data_gen.flow_from_directory(\n",
        "        '1/test',\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "# create model structure\n",
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network/model\n",
        "emotion_model_info = emotion_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=28709 // 64,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=7178 // 64)\n",
        "\n",
        "# save model structure in jason file\n",
        "model_json = emotion_model.to_json()\n",
        "with open(\"emotion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# save trained model weight in .h5 file\n",
        "emotion_model.save_weights('emotion_model.weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5JkiNoBjJx-",
        "outputId": "883d9582-a51a-430c-8046-c58f0192818e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.2429 - loss: 1.8290 - val_accuracy: 0.3617 - val_loss: 1.6875\n",
            "Epoch 2/50\n",
            "\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2656 - loss: 1.7267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2656 - loss: 1.7267 - val_accuracy: 0.2000 - val_loss: 1.8268\n",
            "Epoch 3/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.3519 - loss: 1.6492 - val_accuracy: 0.4182 - val_loss: 1.5378\n",
            "Epoch 4/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44us/step - accuracy: 0.3438 - loss: 1.6750 - val_accuracy: 0.4000 - val_loss: 1.7657\n",
            "Epoch 5/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.4053 - loss: 1.5353 - val_accuracy: 0.4445 - val_loss: 1.4601\n",
            "Epoch 6/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4062 - loss: 1.5592 - val_accuracy: 0.5000 - val_loss: 1.3009\n",
            "Epoch 7/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.4438 - loss: 1.4580 - val_accuracy: 0.4775 - val_loss: 1.3910\n",
            "Epoch 8/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.4219 - loss: 1.4481 - val_accuracy: 0.3000 - val_loss: 1.5181\n",
            "Epoch 9/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.4688 - loss: 1.3902 - val_accuracy: 0.4941 - val_loss: 1.3311\n",
            "Epoch 10/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4844 - loss: 1.3925 - val_accuracy: 0.4000 - val_loss: 1.3750\n",
            "Epoch 11/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.4943 - loss: 1.3325 - val_accuracy: 0.5075 - val_loss: 1.2963\n",
            "Epoch 12/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.4844 - loss: 1.2704 - val_accuracy: 0.5000 - val_loss: 1.1521\n",
            "Epoch 13/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.5100 - loss: 1.2993 - val_accuracy: 0.5220 - val_loss: 1.2608\n",
            "Epoch 14/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 1.0986 - val_accuracy: 0.7000 - val_loss: 1.1467\n",
            "Epoch 15/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.5275 - loss: 1.2545 - val_accuracy: 0.5325 - val_loss: 1.2374\n",
            "Epoch 16/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.5781 - loss: 1.2544 - val_accuracy: 0.3000 - val_loss: 1.8713\n",
            "Epoch 17/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.5400 - loss: 1.2272 - val_accuracy: 0.5417 - val_loss: 1.2076\n",
            "Epoch 18/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.5625 - loss: 1.0687 - val_accuracy: 0.3000 - val_loss: 1.7948\n",
            "Epoch 19/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.5486 - loss: 1.1933 - val_accuracy: 0.5494 - val_loss: 1.1873\n",
            "Epoch 20/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.6406 - loss: 0.8992 - val_accuracy: 0.7000 - val_loss: 0.8802\n",
            "Epoch 21/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - accuracy: 0.5703 - loss: 1.1639 - val_accuracy: 0.5562 - val_loss: 1.1694\n",
            "Epoch 22/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.5625 - loss: 1.2559 - val_accuracy: 0.5000 - val_loss: 1.3316\n",
            "Epoch 23/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.5772 - loss: 1.1322 - val_accuracy: 0.5660 - val_loss: 1.1521\n",
            "Epoch 24/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.5312 - loss: 1.1310 - val_accuracy: 0.7000 - val_loss: 1.1267\n",
            "Epoch 25/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.5828 - loss: 1.1042 - val_accuracy: 0.5679 - val_loss: 1.1402\n",
            "Epoch 26/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 0.8546 - val_accuracy: 0.2000 - val_loss: 1.9706\n",
            "Epoch 27/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 1.0764 - val_accuracy: 0.5762 - val_loss: 1.1270\n",
            "Epoch 28/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.7344 - loss: 0.7837 - val_accuracy: 0.8000 - val_loss: 1.0467\n",
            "Epoch 29/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6041 - loss: 1.0543 - val_accuracy: 0.5714 - val_loss: 1.1285\n",
            "Epoch 30/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 1.1038 - val_accuracy: 0.6000 - val_loss: 1.0462\n",
            "Epoch 31/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6182 - loss: 1.0315 - val_accuracy: 0.5840 - val_loss: 1.1031\n",
            "Epoch 32/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7188 - loss: 0.8322 - val_accuracy: 0.8000 - val_loss: 0.8732\n",
            "Epoch 33/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6268 - loss: 1.0022 - val_accuracy: 0.5769 - val_loss: 1.1171\n",
            "Epoch 34/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.6094 - loss: 1.0954 - val_accuracy: 0.7000 - val_loss: 0.7113\n",
            "Epoch 35/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.6399 - loss: 0.9783 - val_accuracy: 0.5894 - val_loss: 1.0952\n",
            "Epoch 36/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.5781 - loss: 1.0523 - val_accuracy: 0.6000 - val_loss: 1.5804\n",
            "Epoch 37/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.6435 - loss: 0.9600 - val_accuracy: 0.5928 - val_loss: 1.0914\n",
            "Epoch 38/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177us/step - accuracy: 0.6562 - loss: 0.8412 - val_accuracy: 0.3000 - val_loss: 1.2246\n",
            "Epoch 39/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.6552 - loss: 0.9411 - val_accuracy: 0.5938 - val_loss: 1.0840\n",
            "Epoch 40/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.9686 - val_accuracy: 0.5000 - val_loss: 1.0154\n",
            "Epoch 41/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 31ms/step - accuracy: 0.6705 - loss: 0.8941 - val_accuracy: 0.5953 - val_loss: 1.0754\n",
            "Epoch 42/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.7656 - loss: 0.7364 - val_accuracy: 0.6000 - val_loss: 0.9531\n",
            "Epoch 43/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.6764 - loss: 0.8736 - val_accuracy: 0.5970 - val_loss: 1.0749\n",
            "Epoch 44/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.5781 - loss: 1.0736 - val_accuracy: 0.6000 - val_loss: 1.2126\n",
            "Epoch 45/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.6829 - loss: 0.8631 - val_accuracy: 0.6049 - val_loss: 1.0701\n",
            "Epoch 46/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.5781 - loss: 1.1718 - val_accuracy: 0.6000 - val_loss: 0.6987\n",
            "Epoch 47/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.6931 - loss: 0.8350 - val_accuracy: 0.6078 - val_loss: 1.0654\n",
            "Epoch 48/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.7344 - loss: 0.7527 - val_accuracy: 0.7000 - val_loss: 0.9555\n",
            "Epoch 49/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.7093 - loss: 0.8051 - val_accuracy: 0.6071 - val_loss: 1.0672\n",
            "Epoch 50/50\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55us/step - accuracy: 0.6875 - loss: 0.7326 - val_accuracy: 0.6000 - val_loss: 1.2443\n"
          ]
        }
      ]
    }
  ]
}